model: local
local_model:
  repo_id: bartowski/Meta-Llama-3.1-8B-Instruct-GGUF
  filename: "*Q4_K_M.gguf"
  n_ctx: 4096
num_scenarios: 2
num_choices: 2
kdma_theme: merit
scenario_id: generated-merit
temperature: 0.8
max_tokens: 2000
output: output/scenarios.json
